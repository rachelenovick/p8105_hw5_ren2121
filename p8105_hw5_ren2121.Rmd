---
title: "p8105_hw5_ren2121"
output: github_document
date: "2025-11-09"
---

```{r}
library(tidyverse)
library(knitr)
```


## Problem 1

Writing a function to randomly draw birthdays and check whether birthdays have been repeated:

```{r}
bday_sim = function (n_room) {
  
  birthdays = sample(1:365, n_room, replace = TRUE) 

  repeated_bday = length(unique(birthdays)) < n_room
  
  repeated_bday
  
}

bday_sim_results =
  expand_grid(
    group_size = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(group_size, bday_sim)
  ) |> 
  group_by(
    group_size
  ) |> 
  summarize(
    prob_repeat = mean(result)
  )

```

Plotting the probability as a function of group size:

```{r}
bday_sim_results |> 
  ggplot(aes(x = group_size, y = prob_repeat)) +
  geom_point() +
  geom_line() +
  labs(
    x = "Group Size",
    y = "Probability of Repeated Birthdays",
    title = "Probability of Repeated Birthdays vs. Group Size"
  )

```
The plot follows a roughly S-shaped curve, demonstrating that as group size increases, the probability of two individuals having the same birthday increases at first steeply, and then asymptotically approaches a probability of 1.


## Problem 2

```{r}
#Writing a function

sim_ttest = function(mu){
  
  n = 30
  sigma = 5
  x = rnorm(n = n, mean = mu, sd = sigma)
 
t.test(x, mu = 0) |> 
   broom::tidy() |> 
   select(estimate, p.value)
  
}

set.seed(3) #my favorite number

#Generating 5000 datasets for mu = 0
mu_zero =
  expand_grid(
    mu_true = 0,
    iter = 1:5000
  )
mu_zero_results_df = 
  mu_zero |> 
  mutate(
    results = map(mu_true, sim_ttest)
  ) |> 
  unnest(results)

#Generating 5000 datasets for mu = 0:6
power_df =
  expand_grid(
    mu_true = 0:6,
    iter = 1:5000
  )
power_results_df = 
  power_df |> 
  mutate(
    results = map(mu_true, sim_ttest)
  ) |> 
  unnest(results)
##SHOULD I DO 0:6 OR 1:6?? (ARGUMENT FOR 0:6 - BELOW, I CAN PLOT 0-6 MORE EASILY.)

```

Plotting the proportion of times the null was rejected:

```{r}
power_results_df |> 
  group_by(mu_true) |> 
  summarize(
    power = mean(p.value < 0.05)
  ) |> 
  ggplot(aes(x = mu_true, y = power)) +
    geom_point() + 
    geom_line() +
  labs(
    x = "True Mean",
    y = "Proportion Null Rejected",
    title = "Proportion Null Rejected vs. True Mean"
  )
```
As the true mean increases in value, the proportion of times the null was rejected increases steeply, and then asymptotically approaches 1. 


Plotting the average estimate of mu versus the true mu:

```{r}
power_results_df |> 
  group_by(mu_true) |> 
  summarize(
    avg_estimate = mean(estimate)
  ) |> 
  ggplot(aes(x = mu_true, y = avg_estimate)) +
    geom_point() + 
    geom_line() +
  labs(
    x = "True Mean",
    y = "Average Estimate of Mean",
    title = "Average Estimate of Mean vs. True Mean"
  )
```
The average estimate of ðœ‡Ì‚ increases proportionally with the true mean, and visually, the plot seems to show a perfect correlation. This makes sense because we took the average value from 5000 trials, so we would expect the average across all simulations to very nearly approximate the true mean.

Plotting the average estimate of mu versus the true mu AMONG SAMPLES FOR WHICH NULL WAS REJECTED:

```{r}
power_results_df |> 
  filter(p.value < 0.05) |> 
  group_by(mu_true) |> 
  summarize(
    avg_estimate = mean(estimate),
  ) |> 
  ggplot(aes(x = mu_true, y = avg_estimate)) +
    geom_point() + 
    geom_line() +
  labs(
    x = "True Mean",
    y = "Average Estimate of Mean",
    title = "Average Estimate of Mean vs. True Mean"
  )
```
This plot shows that at lower values of the true mean, the average estimate of the mean was higher than the true mean among samples for which the null was rejected. For true mean values ~ >3, we see that the true mean and the average estimate of the mean closely align.

The sample average of ðœ‡Ì‚ across tests for which the null is rejected was NOT approximately equal to the true value of ðœ‡for lower values, but it was approximately equal at higher values. This makes sense because at low values, the true mean was closer to the null value of 0, therefore only in the trials where the estimate of the mean was higher than the true value was the computed test statistic large enough and the associated p-value small enough to reject the null hypothesis.


## Problem 3

Reading in the dataset from github:

```{r}
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicides = read_csv(url)
```

*Describing the raw data*

The homicide dataset is contains 52179 observations and 12 variables. It contains the following variables that describe each instance of criminal homicide over the past decade in 50 of the largest U.S. cities: `r paste(names(homicides), collapse = ", ")`.

```{r}
homicides =
  homicides |> 
  mutate(
    city_state = paste(city, state, sep = ", ")
  )

homicides |>
  filter(city_state == "Baltimore, MD") |> 
  count()
  
```

There were 2827 homicides in Baltimore, MD in total.

```{r}
homicides |> 
  filter(
    city_state == "Baltimore, MD",
    disposition %in% c("Closed without arrest", "Open/No arrest")) |> 
  count()
  
```

There were 1825 unsolved homicides in Baltimore, MD.

```{r}
baltimore_prop =
  prop.test(x = 1825, n = 2827) |> 
  broom::tidy() |> 
  select(estimate, conf.low, conf.high)
```
WAS THERE A MORE EFFICIENT WAY TO DO THIS??? SEE BELOW: IS MY CODE REDUNDANT???


Running prop.test for each city, extracting the proportion and confidence intervals, and creating a dataframe:

```{r}
unsolved_prop =
  homicides |> 
  group_by(city_state) |> 
  summarise(
    total = n(),
    unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    .groups = "drop"
  )

prop_test = function(x, n) {
  
  prop.test(x = x, n = n) |> 
    broom::tidy() |> 
    select(estimate, conf.low, conf.high)
  
}

homicides_output = 
  unsolved_prop |> 
  mutate(
    prop_results = map2(unsolved, total, prop_test)
  ) |> 
  unnest() 
  
```

Table showing #homicides, #unsolved, proportion unsolved, and confidence limits by city:

```{r}
homicides_output |> 
  kable()
```

Plot of estimates and CIs of proportion of unsolved homicides by city:

```{r}

```








